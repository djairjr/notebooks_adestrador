{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djairjr/notebooks_adestrador/blob/main/Detecta_Objetos_Dog_e_Pee_Salva_SSCMA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ukZs9u95bob"
      },
      "source": [
        "# SSCMA - Detectar Dog e Pee\n",
        "Aqui eu mesclei dois datasets do Roboflow. Um aberto, do Roboflow Universe, que foi usado pela Seeed para o Dog e Cat detector.\n",
        "\n",
        "O sistema importa os dois datasets com anotações no formato YOLO, faz todas as operações de redução de fusão e no final, grava as anotações no formato COCO JSON, que é o formato usado pela SSCMA.\n",
        "\n",
        "Por fim, usa esse material para treinar a rede."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RqSttE-5bof"
      },
      "source": [
        "# Foi baseado no modelo Gender Detection - Swift-YOLO\n",
        "\n",
        "**Version:** 1.0.0\n",
        "\n",
        "**Category:** Object Detection\n",
        "\n",
        "**Algorithm:** [Swift-YOLO](configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py)\n",
        "\n",
        "**Datasets:** [Dog Pee Detect](https://app.roboflow.com/ds/39UHskHG15?key=Fgy5XdrGZz)\n",
        "\n",
        "[Pet Detect](https://universe.roboflow.com/animal-cegrr/animal-ph37i/dataset/13)\n",
        "\n",
        "**Class:** `dog`, `pee`\n",
        "\n",
        "Modelo treinado para detectar Cachorro e Xixi num quadro.\n",
        "\n",
        "No final gera modelo tflite_uint8 Vela, que vai ser importado direto no SenseCraft Ai.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RptflDV55bog"
      },
      "source": [
        "## ⚙️Prerequisitos\n",
        "### Configurar o SSCMA\n",
        "Clonar o [repositorio](https://github.com/Seeed-Studio/ModelAssistant) e instalar as dependencias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grieIJLF5boh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5bc5b62-fb0f-4525-8734-930a3108fd94",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ModelAssistant'...\n",
            "remote: Enumerating objects: 13563, done.\u001b[K\n",
            "remote: Counting objects: 100% (6592/6592), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2177/2177), done.\u001b[K\n",
            "remote: Total 13563 (delta 3982), reused 6029 (delta 3790), pack-reused 6971\u001b[K\n",
            "Receiving objects: 100% (13563/13563), 22.66 MiB | 11.59 MiB/s, done.\n",
            "Resolving deltas: 100% (7944/7944), done.\n",
            "/content/ModelAssistant\n",
            "Checking if CUDA available... \u001b[032mOK\u001b[m\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.0.1\n",
            "  Downloading torchaudio-2.0.1-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.1+cu121\n",
            "    Uninstalling torchvision-0.18.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.3.1+cu121\n",
            "    Uninstalling torchaudio-2.3.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.3.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 triton-2.0.0\n",
            "Installing base deps... Collecting TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (from -r requirements/export.txt (line 2))\n",
            "  Downloading https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.5/416.5 kB\u001b[0m \u001b[31m281.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: albumentations<=1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 2)) (1.3.1)\n",
            "Collecting libusb1 (from -r requirements/base.txt (line 3))\n",
            "  Downloading libusb1-3.1.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cbor (from -r requirements/base.txt (line 7))\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 8)) (1.25.2)\n",
            "Collecting opencv-python>=4.9.0.80 (from -r requirements/base.txt (line 12))\n",
            "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openmim>=0.3.7 (from -r requirements/base.txt (line 16))\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 17)) (24.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 18)) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 19)) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 20)) (6.0.1)\n",
            "Collecting scikit-image>=0.20.0 (from -r requirements/base.txt (line 21))\n",
            "  Downloading scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 22)) (1.2.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 26)) (0.12.1)\n",
            "Requirement already satisfied: tensorboard>=2.12.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 30)) (2.15.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 31)) (4.66.4)\n",
            "Collecting pyvww (from -r requirements/base.txt (line 35))\n",
            "  Downloading pyvww-0.1.1-py3-none-any.whl (8.9 kB)\n",
            "Collecting pnnx==0.0.4 (from -r requirements/inference.txt (line 2))\n",
            "  Downloading pnnx-0.0.4-py3-none-any.whl (49.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ncnn>=1.0.20230517 (from -r requirements/inference.txt (line 3))\n",
            "  Downloading ncnn-1.0.20240410-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx>=1.14.0 (from -r requirements/inference.txt (line 4))\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxmltools>=1.11.2 (from -r requirements/inference.txt (line 5))\n",
            "  Downloading onnxmltools-1.12.0-py2.py3-none-any.whl (329 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.0/329.0 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.15.1 (from -r requirements/inference.txt (line 6))\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxsim>=0.4.33 (from -r requirements/inference.txt (line 7))\n",
            "  Downloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf>=4.23.3 (from -r requirements/inference.txt (line 8))\n",
            "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.3/309.3 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/inference.txt (line 9)) (2.15.0)\n",
            "Collecting ethos-u-vela (from -r requirements/export.txt (line 8))\n",
            "  Downloading ethos_u_vela-3.12.0.tar.gz (407 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.8/407.8 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting black>=23.3.0 (from -r requirements/tests.txt (line 1))\n",
            "  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort>=5.12.0 (from -r requirements/tests.txt (line 2))\n",
            "  Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pre-commit>=3.3.3 (from -r requirements/tests.txt (line 3))\n",
            "  Downloading pre_commit-3.7.1-py2.py3-none-any.whl (204 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/204.3 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ruff>=0.0.275 (from -r requirements/tests.txt (line 4))\n",
            "  Downloading ruff-0.5.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->-r requirements/base.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->-r requirements/base.txt (line 2)) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->-r requirements/base.txt (line 2)) (4.10.0.84)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (8.1.7)\n",
            "Collecting colorama (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (2.31.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (13.7.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 16)) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 18)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 18)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 18)) (2024.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 21)) (3.3)\n",
            "Collecting imageio>=2.33 (from scikit-image>=0.20.0->-r requirements/base.txt (line 21))\n",
            "  Downloading imageio-2.34.2-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 21)) (2024.7.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 21)) (0.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->-r requirements/base.txt (line 22)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->-r requirements/base.txt (line 22)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->-r requirements/base.txt (line 26)) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (3.0.3)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from pyvww->-r requirements/base.txt (line 35)) (2.0.8)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from pyvww->-r requirements/base.txt (line 35)) (0.15.1)\n",
            "Collecting portalocker (from ncnn>=1.0.20230517->-r requirements/inference.txt (line 3))\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6)) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6)) (1.13.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (3.3.0)\n",
            "Collecting protobuf>=4.23.3 (from -r requirements/inference.txt (line 8))\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (2.15.0)\n",
            "Collecting ruamel.yaml>=0.16.12 (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting igraph>=0.9 (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading igraph-0.11.6-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6))\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ethos-u-vela->-r requirements/export.txt (line 8)) (4.9.4)\n",
            "Collecting mypy-extensions>=0.4.3 (from black>=23.3.0->-r requirements/tests.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black>=23.3.0->-r requirements/tests.txt (line 1))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->-r requirements/tests.txt (line 1)) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->-r requirements/tests.txt (line 1)) (2.0.1)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading identify-2.6.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodeenv>=0.11.1 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading virtualenv-20.26.3-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.43.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->-r requirements/base.txt (line 26)) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (1.3.1)\n",
            "Collecting texttable>=1.6.2 (from igraph>=0.9->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16)) (2024.7.4)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.16.12->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3)) (3.15.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (2.1.5)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.15.1->-r requirements/inference.txt (line 6))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ordered-set (from model-index->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openxlab (from opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading openxlab-0.1.1-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.6/308.6 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->pyvww->-r requirements/base.txt (line 35)) (3.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim>=0.3.7->-r requirements/base.txt (line 16)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim>=0.3.7->-r requirements/base.txt (line 16)) (2.16.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.15.1->-r requirements/inference.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->pyvww->-r requirements/base.txt (line 35)) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 35)) (18.1.8)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim>=0.3.7->-r requirements/base.txt (line 16)) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 35)) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.12.3->-r requirements/base.txt (line 30)) (3.2.2)\n",
            "Collecting filelock<4,>=3.12.2 (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich (from openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools>=41.0.0 (from tensorboard>=2.12.3->-r requirements/base.txt (line 30))\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm>=4.65.0 (from -r requirements/base.txt (line 31))\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading aliyun_python_sdk_kms-2.16.3-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading aliyun-python-sdk-core-2.15.1.tar.gz (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16))\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 16)) (42.0.8)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'pnnx' candidate (version 0.0.4 at https://files.pythonhosted.org/packages/2a/61/e70626f1e94026da417e6ecd5ad303d0ef3fe7a32fb3fff821bb07f1f4e2/pnnx-0.0.4-py3-none-any.whl (from https://pypi.org/simple/pnnx/))\n",
            "Reason for being yanked: <none given>\u001b[0m\u001b[33m\n",
            "\u001b[0mBuilding wheels for collected packages: cbor, ethos-u-vela, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53432 sha256=53fe67d47b0bf441347387a231ab11e056cd335d0136497302fe7c78902b81d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\n",
            "  Building wheel for ethos-u-vela (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ethos-u-vela: filename=ethos_u_vela-3.12.0-cp310-cp310-linux_x86_64.whl size=623072 sha256=1afb251192baebdecaaa972750a6f4e5f33b01e39152cc5ab106fac32baa95ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/08/cd/d82ac308858502706f1d777f6bdda8b4f6f985f8f1c07ff139\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112372 sha256=9b087d1669766fa2869d2d41d549e052bb09d89a833474327079a2801a78dabb\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.15.1-py3-none-any.whl size=535325 sha256=3b72b66d415f4d6233d36d92da665bcd585f7431ddb2fba4a94e4e9b74d4858c\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/4b/8e/0a28e00f4cf43b273c18cce083804738d41013e017da922ce4\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31410 sha256=2c949ffb15f40ec5be0f6291c3f52f30b878a79aee1274230efd01613a36b697\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built cbor ethos-u-vela oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: texttable, pnnx, libusb1, flatbuffers, distlib, crcmod, cbor, urllib3, tqdm, setuptools, ruff, ruamel.yaml.clib, pycryptodome, protobuf, portalocker, pathspec, ordered-set, opencv-python, nodeenv, mypy-extensions, jmespath, isort, imageio, igraph, identify, humanfriendly, filelock, ethos-u-vela, colorama, cfgv, virtualenv, scikit-image, ruamel.yaml, rich, requests, onnx, model-index, coloredlogs, black, TinyNeuralNetwork, pre-commit, onnxsim, onnxruntime, onnxmltools, ncnn, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim, pyvww\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 24.3.25\n",
            "    Uninstalling flatbuffers-24.3.25:\n",
            "      Successfully uninstalled flatbuffers-24.3.25\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.4\n",
            "    Uninstalling tqdm-4.66.4:\n",
            "      Successfully uninstalled tqdm-4.66.4\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.31.6\n",
            "    Uninstalling imageio-2.31.6:\n",
            "      Successfully uninstalled imageio-2.31.6\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.15.4\n",
            "    Uninstalling filelock-3.15.4:\n",
            "      Successfully uninstalled filelock-3.15.4\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.19.3\n",
            "    Uninstalling scikit-image-0.19.3:\n",
            "      Successfully uninstalled scikit-image-0.19.3\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.1\n",
            "    Uninstalling rich-13.7.1:\n",
            "      Successfully uninstalled rich-13.7.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "cvxpy 1.3.4 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.0 which is incompatible.\n",
            "yfinance 0.2.40 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TinyNeuralNetwork-0.1.1 aliyun-python-sdk-core-2.15.1 aliyun-python-sdk-kms-2.16.3 black-24.4.2 cbor-1.0.0 cfgv-3.4.0 colorama-0.4.6 coloredlogs-15.0.1 crcmod-1.7 distlib-0.3.8 ethos-u-vela-3.12.0 filelock-3.14.0 flatbuffers-23.5.26 humanfriendly-10.0 identify-2.6.0 igraph-0.11.6 imageio-2.34.2 isort-5.13.2 jmespath-0.10.0 libusb1-3.1.0 model-index-0.1.11 mypy-extensions-1.0.0 ncnn-1.0.20240410 nodeenv-1.9.1 onnx-1.16.1 onnxmltools-1.12.0 onnxruntime-1.18.1 onnxsim-0.4.36 opencv-python-4.10.0.84 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.1.1 ordered-set-4.1.0 oss2-2.17.0 pathspec-0.12.1 pnnx-0.0.4 portalocker-2.10.1 pre-commit-3.7.1 protobuf-4.25.3 pycryptodome-3.20.0 pyvww-0.1.1 requests-2.28.2 rich-13.4.2 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 ruff-0.5.4 scikit-image-0.24.0 setuptools-60.2.0 texttable-1.7.0 tqdm-4.65.2 urllib3-1.26.19 virtualenv-20.26.3\n",
            "Installing OpenMIM deps... \n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Collecting mmcls>=1.0.0.rc6 (from -r requirements/mmlab.txt (line 2))\n",
            "  Downloading mmcls-1.0.0rc6-py2.py3-none-any.whl (906 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.1/906.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmcv-full<=2.1.0 (from -r requirements/mmlab.txt (line 3))\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv_full-1.7.2-cp310-cp310-manylinux1_x86_64.whl (70.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmdet<3.1.0,>=3.0.0 (from -r requirements/mmlab.txt (line 4))\n",
            "  Downloading mmdet-3.0.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmengine>=0.8.2 (from -r requirements/mmlab.txt (line 5))\n",
            "  Downloading mmengine-0.10.4-py3-none-any.whl (451 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.7.1)\n",
            "Collecting modelindex (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2))\n",
            "  Downloading modelindex-0.0.2-py3-none-any.whl (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (24.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (13.4.2)\n",
            "Collecting mmcv<=2.1.0,>=2.0.0rc4 (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2))\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv-2.1.0-cp310-cp310-manylinux1_x86_64.whl (98.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (6.0.1)\n",
            "Collecting yapf (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3))\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (4.10.0.84)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (2.0.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (2.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (1.16.0)\n",
            "Collecting terminaltables (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4))\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Collecting mmcv<=2.1.0,>=2.0.0rc4 (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2))\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv-2.0.1-cp310-cp310-manylinux1_x86_64.whl (74.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.8.2->-r requirements/mmlab.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.1.11)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (8.0.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (4.2.2)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (3.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (4.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (8.1.7)\n",
            "Installing collected packages: addict, terminaltables, yapf, modelindex, mmengine, mmcv-full, mmcv, mmdet, mmcls\n",
            "Successfully installed addict-2.4.0 mmcls-1.0.0rc6 mmcv-2.0.1 mmcv-full-1.7.2 mmdet-3.0.0 mmengine-0.10.4 modelindex-0.0.2 terminaltables-3.1.10 yapf-0.40.2\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Obtaining file:///content/ModelAssistant\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (from sscma==2.0.0rc3)\n",
            "  Using cached https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (416 kB)\n",
            "Requirement already satisfied: torch<=2.0.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.0.0)\n",
            "Requirement already satisfied: torchaudio<=2.0.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.0.1)\n",
            "Requirement already satisfied: torchvision<=0.15.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.15.1)\n",
            "Requirement already satisfied: albumentations<=1.3.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.3.1)\n",
            "Requirement already satisfied: libusb1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.1.0)\n",
            "Requirement already satisfied: cbor in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.25.2)\n",
            "Requirement already satisfied: opencv-python>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.10.0.84)\n",
            "Requirement already satisfied: openmim>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.3.9)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (24.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (6.0.1)\n",
            "Requirement already satisfied: scikit-image>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.24.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.2.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: tensorboard>=2.12.3 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.15.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.65.2)\n",
            "Requirement already satisfied: pyvww in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.1.1)\n",
            "Requirement already satisfied: pnnx==0.0.4 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.0.4)\n",
            "Requirement already satisfied: ncnn>=1.0.20230517 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.0.20240410)\n",
            "Requirement already satisfied: onnx>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.16.1)\n",
            "Requirement already satisfied: onnxmltools>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.12.0)\n",
            "Requirement already satisfied: onnxruntime>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.18.1)\n",
            "Requirement already satisfied: onnxsim>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.4.36)\n",
            "Requirement already satisfied: protobuf>=4.23.3 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.25.3)\n",
            "Requirement already satisfied: tensorflow>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.15.0)\n",
            "Requirement already satisfied: ethos-u-vela in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.12.0)\n",
            "Requirement already satisfied: black>=23.3.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (24.4.2)\n",
            "Requirement already satisfied: isort>=5.12.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (5.13.2)\n",
            "Requirement already satisfied: pre-commit>=3.3.3 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.7.1)\n",
            "Requirement already satisfied: ruff>=0.0.275 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.5.4)\n",
            "Requirement already satisfied: mmcls>=1.0.0.rc6 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.0.0rc6)\n",
            "Requirement already satisfied: mmcv-full<=2.1.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.7.2)\n",
            "Requirement already satisfied: mmdet<3.1.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.0.0)\n",
            "Requirement already satisfied: mmengine>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.10.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->sscma==2.0.0rc3) (1.11.4)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->sscma==2.0.0rc3) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations<=1.3.1->sscma==2.0.0rc3) (4.10.0.84)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (4.12.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.7.1)\n",
            "Requirement already satisfied: modelindex in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (13.4.2)\n",
            "Requirement already satisfied: mmcv<=2.1.0,>=2.0.0rc4 in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (2.0.1)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->sscma==2.0.0rc3) (2.4.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv-full<=2.1.0->sscma==2.0.0rc3) (0.40.2)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (2.0.8)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (2.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (1.16.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (3.1.10)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.8.2->sscma==2.0.0rc3) (2.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ncnn>=1.0.20230517->sscma==2.0.0rc3) (2.28.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from ncnn>=1.0.20230517->sscma==2.0.0rc3) (2.10.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (23.5.26)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (1.13.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.0.10)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (23.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2024.1)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (2.6.0)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (1.9.1)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (20.26.3)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (2024.7.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (0.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->sscma==2.0.0rc3) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->sscma==2.0.0rc3) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->sscma==2.0.0rc3) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (60.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (3.0.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (3.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (3.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<=2.0.1->sscma==2.0.0rc3) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<=2.0.1->sscma==2.0.0rc3) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<=2.0.1->sscma==2.0.0rc3) (18.1.8)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ethos-u-vela->sscma==2.0.0rc3) (4.9.4)\n",
            "Requirement already satisfied: ruamel.yaml>=0.16.12 in /usr/local/lib/python3.10/dist-packages (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.18.6)\n",
            "Requirement already satisfied: igraph>=0.9 in /usr/local/lib/python3.10/dist-packages (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.11.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->sscma==2.0.0rc3) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->sscma==2.0.0rc3) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->sscma==2.0.0rc3) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->sscma==2.0.0rc3) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.12.3->sscma==2.0.0rc3) (1.3.1)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from igraph>=0.9->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (3.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (2024.7.4)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.16.12->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.2.8)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->sscma==2.0.0rc3) (0.3.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.12.3->sscma==2.0.0rc3) (2.1.5)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.15.1->sscma==2.0.0rc3) (10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.1.2)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->openmim>=0.3.7->sscma==2.0.0rc3) (4.1.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (3.20.0)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (0.1.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (2.16.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.15.1->sscma==2.0.0rc3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full<=2.1.0->sscma==2.0.0rc3) (8.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full<=2.1.0->sscma==2.0.0rc3) (3.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.12.3->sscma==2.0.0rc3) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.12.3->sscma==2.0.0rc3) (3.2.2)\n",
            "Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.17.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (1.7)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.16.3)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.15.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (42.0.8)\n",
            "Building wheels for collected packages: sscma\n",
            "  Building editable for sscma (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sscma: filename=sscma-2.0.0rc3-0.editable-py3-none-any.whl size=11132 sha256=1e118e5e935d801701b1bbfa4362519b0ec30ae2bde120014902952bd2ac8ac0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g30awzko/wheels/90/1c/ba/0dcfb496beef1b933cf590042cc252e1a365a514ee48989a82\n",
            "Successfully built sscma\n",
            "Installing collected packages: sscma\n",
            "Successfully installed sscma-2.0.0rc3\n",
            "Finished setup... \u001b[032mOK\u001b[m\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Seeed-Studio/ModelAssistant.git   #clone the repo\n",
        "%cd ModelAssistant\n",
        "!. ./scripts/setup_colab.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r4g-Z6H5boi"
      },
      "source": [
        "### Monta Pasta do Google Drive com Dataset do Roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUiZRXY_5boj",
        "outputId": "8e2209d6-3b5f-442c-ac52-13af703a2355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Vai pedir confirmação para montar a pasta do Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJDSrxJR3j5E",
        "outputId": "bafa8124-d7b5-4a9d-9792-2cb1ea3b3e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "# Vai para a pasta do Google Drive Montada\n",
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YajZT9zJ3x5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93478c8f-cc31-4b78-cdfb-e98c5615eb48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "# Primeiro baixa os datasets com anotações no formato YoloV5\n",
        "!pip install -q roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"kotWwID7uvzzuksoQbVk\")\n",
        "project = rf.workspace(\"dogs-mzyyn\").project(\"dogstainamplified\")\n",
        "version = project.version(5)\n",
        "dataset = version.download(\"coco\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H39pXEzn5boj"
      },
      "source": [
        "## 🚀Train a model with SSCMA\n",
        "All the training parameters are in the `config.py` file, you can change the parameters to train your own model.\n",
        "\n",
        "Below are explanations of some common parameters. You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/config) for more details.\n",
        "- `data_root` - the datasets path.\n",
        "- `epochs`- the train epochs. **we use 10 epochs as an example**.\n",
        "- `batch_size` - the batch size.\n",
        "- `height` - the image height.\n",
        "- `width` - the image width.\n",
        "- `load_from` - the pretrained model path.\n",
        "- `num_classes` - the number of classes.\n",
        "\n",
        "You can overwrite the parameters in the `config.py` file by using the `--cfg-options` argument.\n",
        "```bash\n",
        "# Example\n",
        "sscma.train config.py --cfg-options data_root=./datasets/test_dataset epochs=10\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEhRzV285boj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24de9a1e-3f2e-45da-c930-b204f19f462a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n",
            "\u001b[0m\u001b[01;34mMyDrive\u001b[0m/\n",
            "/content/ModelAssistant\n",
            "Using automatically generated input shape (from config 'fomo_mobnetv2_0.35_x8_abl_coco.py'): [1, 3, 192, 192]\n",
            "07/22 11:37:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 364761872\n",
            "    GPU 0: NVIDIA L4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.10.0\n",
            "    MMEngine: 0.10.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 364761872\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "07/22 11:37:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "albu_train_transforms = [\n",
            "    dict(limit=30, type='Rotate'),\n",
            "    dict(\n",
            "        brightness_limit=0.3,\n",
            "        contrast_limit=0.3,\n",
            "        p=0.5,\n",
            "        type='RandomBrightnessContrast'),\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "    dict(p=0.5, type='HorizontalFlip'),\n",
            "]\n",
            "batch = 16\n",
            "custom_imports = dict(\n",
            "    allow_failed_imports=False, imports=[\n",
            "        'sscma',\n",
            "    ])\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        0,\n",
            "        0,\n",
            "        0,\n",
            "    ],\n",
            "    pad_size_divisor=32,\n",
            "    std=[\n",
            "        255.0,\n",
            "        255.0,\n",
            "        255.0,\n",
            "    ],\n",
            "    type='mmdet.DetDataPreprocessor')\n",
            "data_root = '/content/drive/MyDrive/DogStainAmplified-5'\n",
            "dataset_type = 'CustomFomoCocoDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(interval=5, type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(score_thr=0.8, type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 100\n",
            "find_unused_parameters = True\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "input_type = 'image'\n",
            "launcher = 'none'\n",
            "load_from = None\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "lr = 0.001\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        out_indices=(2, ), rep=True, type='MobileNetv2', widen_factor=0.35),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0,\n",
            "            0,\n",
            "            0,\n",
            "        ],\n",
            "        pad_size_divisor=32,\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    head=dict(\n",
            "        act_cfg='ReLU6',\n",
            "        input_channels=[\n",
            "            32,\n",
            "        ],\n",
            "        loss_bg=dict(reduction='none', type='BCEWithLogitsLoss'),\n",
            "        loss_cls=dict(\n",
            "            pos_weight=40, reduction='none', type='BCEWithLogitsLoss'),\n",
            "        middle_channel=48,\n",
            "        num_classes=2,\n",
            "        type='FomoHead'),\n",
            "    skip_preprocessor=True,\n",
            "    type='Fomo')\n",
            "momentum = (\n",
            "    0.9,\n",
            "    0.99,\n",
            ")\n",
            "num_classes = 2\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(\n",
            "        betas=(\n",
            "            0.9,\n",
            "            0.99,\n",
            "        ),\n",
            "        eps=1e-07,\n",
            "        lr=0.001,\n",
            "        type='Adam',\n",
            "        weight_decay=0.0005))\n",
            "param_scheduler = [\n",
            "    dict(begin=0, by_epoch=False, end=30, start_factor=0.001, type='LinearLR'),\n",
            "    dict(\n",
            "        begin=1,\n",
            "        by_epoch=True,\n",
            "        end=500,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            100,\n",
            "            200,\n",
            "            250,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "resume = False\n",
            "save_interval = 5\n",
            "test_cfg = dict()\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='/content/drive/MyDrive/DogStainAmplified-5',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='mmdet.Resize'),\n",
            "            dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'fomo_mask',\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='CustomFomoCocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(round_up=False, shuffle=True, type='DefaultSampler'))\n",
            "test_evaluator = dict(type='FomoMetric')\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='mmdet.Resize'),\n",
            "    dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'fomo_mask',\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(by_epoch=True, max_epochs=100, val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='/content/drive/MyDrive/DogStainAmplified-5',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='mmdet.Resize'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(limit=30, type='Rotate'),\n",
            "                    dict(\n",
            "                        brightness_limit=0.3,\n",
            "                        contrast_limit=0.3,\n",
            "                        p=0.5,\n",
            "                        type='RandomBrightnessContrast'),\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                    dict(p=0.5, type='HorizontalFlip'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'fomo_mask',\n",
            "                    'img_path',\n",
            "                    'img_id',\n",
            "                    'instances',\n",
            "                    'img_shape',\n",
            "                    'ori_shape',\n",
            "                    'gt_bboxes',\n",
            "                    'gt_bboxes_labels',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='CustomFomoCocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(round_up=False, shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='mmdet.Resize'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(limit=30, type='Rotate'),\n",
            "            dict(\n",
            "                brightness_limit=0.3,\n",
            "                contrast_limit=0.3,\n",
            "                p=0.5,\n",
            "                type='RandomBrightnessContrast'),\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "            dict(p=0.5, type='HorizontalFlip'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'fomo_mask',\n",
            "            'img_path',\n",
            "            'img_id',\n",
            "            'instances',\n",
            "            'img_shape',\n",
            "            'ori_shape',\n",
            "            'gt_bboxes',\n",
            "            'gt_bboxes_labels',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 1\n",
            "val_cfg = dict()\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='/content/drive/MyDrive/DogStainAmplified-5',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='mmdet.Resize'),\n",
            "            dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'fomo_mask',\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='CustomFomoCocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(round_up=False, shuffle=True, type='DefaultSampler'))\n",
            "val_evaluator = dict(type='FomoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 1\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    fomo=True,\n",
            "    name='visualizer',\n",
            "    type='FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.35\n",
            "width = 192\n",
            "work_dir = 'Dog_Pee_Detect'\n",
            "workers = 1\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/Dog_Pee_Detect/20240722_113726'}\n",
            "2024-07-22 11:37:28.107124: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-07-22 11:37:28.160663: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-22 11:37:28.160711: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-22 11:37:28.162254: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-22 11:37:28.170234: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-22 11:37:29.485571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "07/22 11:37:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "07/22 11:37:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "07/22 11:37:42 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class FomoMetric.\n",
            "[1, 3, 192, 192]\n",
            "07/22 11:37:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::hardtanh encountered 1 time(s)\n",
            "07/22 11:37:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::hardtanh_ encountered 1 time(s)\n",
            "07/22 11:37:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::softmax encountered 1 time(s)\n",
            "07/22 11:37:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "backbone.layer1.0.conv.0, backbone.layer1.0.conv.0.conv, backbone.layer1.0.conv.0.norm, backbone.layer1.0.conv.1, backbone.layer1.0.conv.1.conv, backbone.layer1.0.conv.1.norm, backbone.layer1.0.conv.2, backbone.layer1.0.conv.2.conv, backbone.layer1.0.conv.2.norm, backbone.layer1.0.conv.3, backbone.layer1.0.conv.3.conv, backbone.layer1.0.conv.3.norm, backbone.layer1.0.conv.4, backbone.layer1.0.conv.4.conv, backbone.layer1.0.conv.4.norm, backbone.layer1.0.conv.5, backbone.layer1.0.conv.5.conv, backbone.layer1.0.conv.5.norm, backbone.layer1.0.conv3x3, backbone.layer1.0.conv3x3.conv, backbone.layer1.0.conv3x3.norm, backbone.layer1.0.dense_norm, backbone.layer1.0.norm.0, backbone.layer1.0.norm.1, backbone.layer1.0.norm.2, backbone.layer1.0.norm.3, backbone.layer1.0.norm.4, backbone.layer1.0.norm.5, backbone.layer2.0.conv.0, backbone.layer2.0.conv.0.conv, backbone.layer2.0.conv.0.norm, backbone.layer2.0.conv.1, backbone.layer2.0.conv.1.conv, backbone.layer2.0.conv.1.norm, backbone.layer2.0.conv.2, backbone.layer2.0.conv.2.conv, backbone.layer2.0.conv.2.norm, backbone.layer2.0.conv.3, backbone.layer2.0.conv.3.conv, backbone.layer2.0.conv.3.norm, backbone.layer2.0.conv.4, backbone.layer2.0.conv.4.conv, backbone.layer2.0.conv.4.norm, backbone.layer2.0.conv.5, backbone.layer2.0.conv.5.conv, backbone.layer2.0.conv.5.norm, backbone.layer2.0.conv3x3, backbone.layer2.0.conv3x3.conv, backbone.layer2.0.conv3x3.norm, backbone.layer2.0.dense_norm, backbone.layer2.0.norm.0, backbone.layer2.0.norm.1, backbone.layer2.0.norm.2, backbone.layer2.0.norm.3, backbone.layer2.0.norm.4, backbone.layer2.0.norm.5, backbone.layer2.1.conv.0, backbone.layer2.1.conv.0.conv, backbone.layer2.1.conv.0.norm, backbone.layer2.1.conv.1, backbone.layer2.1.conv.1.conv, backbone.layer2.1.conv.1.norm, backbone.layer2.1.conv.2, backbone.layer2.1.conv.2.conv, backbone.layer2.1.conv.2.norm, backbone.layer2.1.conv.3, backbone.layer2.1.conv.3.conv, backbone.layer2.1.conv.3.norm, backbone.layer2.1.conv.4, backbone.layer2.1.conv.4.conv, backbone.layer2.1.conv.4.norm, backbone.layer2.1.conv.5, backbone.layer2.1.conv.5.conv, backbone.layer2.1.conv.5.norm, backbone.layer2.1.conv3x3, backbone.layer2.1.conv3x3.conv, backbone.layer2.1.conv3x3.norm, backbone.layer2.1.dense_norm, backbone.layer2.1.norm.0, backbone.layer2.1.norm.1, backbone.layer2.1.norm.2, backbone.layer2.1.norm.3, backbone.layer2.1.norm.4, backbone.layer2.1.norm.5, backbone.layer3.0.conv.0, backbone.layer3.0.conv.0.conv, backbone.layer3.0.conv.0.norm, backbone.layer3.0.conv.1, backbone.layer3.0.conv.1.conv, backbone.layer3.0.conv.1.norm, backbone.layer3.0.conv.2, backbone.layer3.0.conv.2.conv, backbone.layer3.0.conv.2.norm, backbone.layer3.0.conv.3, backbone.layer3.0.conv.3.conv, backbone.layer3.0.conv.3.norm, backbone.layer3.0.conv.4, backbone.layer3.0.conv.4.conv, backbone.layer3.0.conv.4.norm, backbone.layer3.0.conv.5, backbone.layer3.0.conv.5.conv, backbone.layer3.0.conv.5.norm, backbone.layer3.0.conv3x3, backbone.layer3.0.conv3x3.conv, backbone.layer3.0.conv3x3.norm, backbone.layer3.0.dense_norm, backbone.layer3.0.norm.0, backbone.layer3.0.norm.1, backbone.layer3.0.norm.2, backbone.layer3.0.norm.3, backbone.layer3.0.norm.4, backbone.layer3.0.norm.5, backbone.layer3.1.conv.0, backbone.layer3.1.conv.0.conv, backbone.layer3.1.conv.0.norm, backbone.layer3.1.conv.1, backbone.layer3.1.conv.1.conv, backbone.layer3.1.conv.1.norm, backbone.layer3.1.conv.2, backbone.layer3.1.conv.2.conv, backbone.layer3.1.conv.2.norm, backbone.layer3.1.conv.3, backbone.layer3.1.conv.3.conv, backbone.layer3.1.conv.3.norm, backbone.layer3.1.conv.4, backbone.layer3.1.conv.4.conv, backbone.layer3.1.conv.4.norm, backbone.layer3.1.conv.5, backbone.layer3.1.conv.5.conv, backbone.layer3.1.conv.5.norm, backbone.layer3.1.conv3x3, backbone.layer3.1.conv3x3.conv, backbone.layer3.1.conv3x3.norm, backbone.layer3.1.dense_norm, backbone.layer3.1.norm.0, backbone.layer3.1.norm.1, backbone.layer3.1.norm.2, backbone.layer3.1.norm.3, backbone.layer3.1.norm.4, backbone.layer3.1.norm.5, backbone.layer3.2.conv.0, backbone.layer3.2.conv.0.conv, backbone.layer3.2.conv.0.norm, backbone.layer3.2.conv.1, backbone.layer3.2.conv.1.conv, backbone.layer3.2.conv.1.norm, backbone.layer3.2.conv.2, backbone.layer3.2.conv.2.conv, backbone.layer3.2.conv.2.norm, backbone.layer3.2.conv.3, backbone.layer3.2.conv.3.conv, backbone.layer3.2.conv.3.norm, backbone.layer3.2.conv.4, backbone.layer3.2.conv.4.conv, backbone.layer3.2.conv.4.norm, backbone.layer3.2.conv.5, backbone.layer3.2.conv.5.conv, backbone.layer3.2.conv.5.norm, backbone.layer3.2.conv3x3, backbone.layer3.2.conv3x3.conv, backbone.layer3.2.conv3x3.norm, backbone.layer3.2.dense_norm, backbone.layer3.2.norm.0, backbone.layer3.2.norm.1, backbone.layer3.2.norm.2, backbone.layer3.2.norm.3, backbone.layer3.2.norm.4, backbone.layer3.2.norm.5, backbone.layer4, backbone.layer4.0, backbone.layer4.0.act, backbone.layer4.0.conv.0, backbone.layer4.0.conv.0.conv, backbone.layer4.0.conv.0.norm, backbone.layer4.0.conv.1, backbone.layer4.0.conv.1.conv, backbone.layer4.0.conv.1.norm, backbone.layer4.0.conv.2, backbone.layer4.0.conv.2.conv, backbone.layer4.0.conv.2.norm, backbone.layer4.0.conv.3, backbone.layer4.0.conv.3.conv, backbone.layer4.0.conv.3.norm, backbone.layer4.0.conv.4, backbone.layer4.0.conv.4.conv, backbone.layer4.0.conv.4.norm, backbone.layer4.0.conv.5, backbone.layer4.0.conv.5.conv, backbone.layer4.0.conv.5.norm, backbone.layer4.0.conv3x3, backbone.layer4.0.conv3x3.conv, backbone.layer4.0.conv3x3.norm, backbone.layer4.0.dense_norm, backbone.layer4.0.fuse_conv, backbone.layer4.0.norm.0, backbone.layer4.0.norm.1, backbone.layer4.0.norm.2, backbone.layer4.0.norm.3, backbone.layer4.0.norm.4, backbone.layer4.0.norm.5, backbone.layer4.1, backbone.layer4.1.act, backbone.layer4.1.conv.0, backbone.layer4.1.conv.0.conv, backbone.layer4.1.conv.0.norm, backbone.layer4.1.conv.1, backbone.layer4.1.conv.1.conv, backbone.layer4.1.conv.1.norm, backbone.layer4.1.conv.2, backbone.layer4.1.conv.2.conv, backbone.layer4.1.conv.2.norm, backbone.layer4.1.conv.3, backbone.layer4.1.conv.3.conv, backbone.layer4.1.conv.3.norm, backbone.layer4.1.conv.4, backbone.layer4.1.conv.4.conv, backbone.layer4.1.conv.4.norm, backbone.layer4.1.conv.5, backbone.layer4.1.conv.5.conv, backbone.layer4.1.conv.5.norm, backbone.layer4.1.conv3x3, backbone.layer4.1.conv3x3.conv, backbone.layer4.1.conv3x3.norm, backbone.layer4.1.dense_norm, backbone.layer4.1.fuse_conv, backbone.layer4.1.norm.0, backbone.layer4.1.norm.1, backbone.layer4.1.norm.2, backbone.layer4.1.norm.3, backbone.layer4.1.norm.4, backbone.layer4.1.norm.5, backbone.layer4.2, backbone.layer4.2.act, backbone.layer4.2.conv.0, backbone.layer4.2.conv.0.conv, backbone.layer4.2.conv.0.norm, backbone.layer4.2.conv.1, backbone.layer4.2.conv.1.conv, backbone.layer4.2.conv.1.norm, backbone.layer4.2.conv.2, backbone.layer4.2.conv.2.conv, backbone.layer4.2.conv.2.norm, backbone.layer4.2.conv.3, backbone.layer4.2.conv.3.conv, backbone.layer4.2.conv.3.norm, backbone.layer4.2.conv.4, backbone.layer4.2.conv.4.conv, backbone.layer4.2.conv.4.norm, backbone.layer4.2.conv.5, backbone.layer4.2.conv.5.conv, backbone.layer4.2.conv.5.norm, backbone.layer4.2.conv3x3, backbone.layer4.2.conv3x3.conv, backbone.layer4.2.conv3x3.norm, backbone.layer4.2.dense_norm, backbone.layer4.2.fuse_conv, backbone.layer4.2.norm.0, backbone.layer4.2.norm.1, backbone.layer4.2.norm.2, backbone.layer4.2.norm.3, backbone.layer4.2.norm.4, backbone.layer4.2.norm.5, backbone.layer4.3, backbone.layer4.3.act, backbone.layer4.3.conv.0, backbone.layer4.3.conv.0.conv, backbone.layer4.3.conv.0.norm, backbone.layer4.3.conv.1, backbone.layer4.3.conv.1.conv, backbone.layer4.3.conv.1.norm, backbone.layer4.3.conv.2, backbone.layer4.3.conv.2.conv, backbone.layer4.3.conv.2.norm, backbone.layer4.3.conv.3, backbone.layer4.3.conv.3.conv, backbone.layer4.3.conv.3.norm, backbone.layer4.3.conv.4, backbone.layer4.3.conv.4.conv, backbone.layer4.3.conv.4.norm, backbone.layer4.3.conv.5, backbone.layer4.3.conv.5.conv, backbone.layer4.3.conv.5.norm, backbone.layer4.3.conv3x3, backbone.layer4.3.conv3x3.conv, backbone.layer4.3.conv3x3.norm, backbone.layer4.3.dense_norm, backbone.layer4.3.fuse_conv, backbone.layer4.3.norm.0, backbone.layer4.3.norm.1, backbone.layer4.3.norm.2, backbone.layer4.3.norm.3, backbone.layer4.3.norm.4, backbone.layer4.3.norm.5, backbone.layer5, backbone.layer5.0, backbone.layer5.0.act, backbone.layer5.0.conv.0, backbone.layer5.0.conv.0.conv, backbone.layer5.0.conv.0.norm, backbone.layer5.0.conv.1, backbone.layer5.0.conv.1.conv, backbone.layer5.0.conv.1.norm, backbone.layer5.0.conv.2, backbone.layer5.0.conv.2.conv, backbone.layer5.0.conv.2.norm, backbone.layer5.0.conv.3, backbone.layer5.0.conv.3.conv, backbone.layer5.0.conv.3.norm, backbone.layer5.0.conv.4, backbone.layer5.0.conv.4.conv, backbone.layer5.0.conv.4.norm, backbone.layer5.0.conv.5, backbone.layer5.0.conv.5.conv, backbone.layer5.0.conv.5.norm, backbone.layer5.0.conv3x3, backbone.layer5.0.conv3x3.conv, backbone.layer5.0.conv3x3.norm, backbone.layer5.0.dense_norm, backbone.layer5.0.fuse_conv, backbone.layer5.0.norm.0, backbone.layer5.0.norm.1, backbone.layer5.0.norm.2, backbone.layer5.0.norm.3, backbone.layer5.0.norm.4, backbone.layer5.0.norm.5, backbone.layer5.1, backbone.layer5.1.act, backbone.layer5.1.conv.0, backbone.layer5.1.conv.0.conv, backbone.layer5.1.conv.0.norm, backbone.layer5.1.conv.1, backbone.layer5.1.conv.1.conv, backbone.layer5.1.conv.1.norm, backbone.layer5.1.conv.2, backbone.layer5.1.conv.2.conv, backbone.layer5.1.conv.2.norm, backbone.layer5.1.conv.3, backbone.layer5.1.conv.3.conv, backbone.layer5.1.conv.3.norm, backbone.layer5.1.conv.4, backbone.layer5.1.conv.4.conv, backbone.layer5.1.conv.4.norm, backbone.layer5.1.conv.5, backbone.layer5.1.conv.5.conv, backbone.layer5.1.conv.5.norm, backbone.layer5.1.conv3x3, backbone.layer5.1.conv3x3.conv, backbone.layer5.1.conv3x3.norm, backbone.layer5.1.dense_norm, backbone.layer5.1.fuse_conv, backbone.layer5.1.norm.0, backbone.layer5.1.norm.1, backbone.layer5.1.norm.2, backbone.layer5.1.norm.3, backbone.layer5.1.norm.4, backbone.layer5.1.norm.5, backbone.layer5.2, backbone.layer5.2.act, backbone.layer5.2.conv.0, backbone.layer5.2.conv.0.conv, backbone.layer5.2.conv.0.norm, backbone.layer5.2.conv.1, backbone.layer5.2.conv.1.conv, backbone.layer5.2.conv.1.norm, backbone.layer5.2.conv.2, backbone.layer5.2.conv.2.conv, backbone.layer5.2.conv.2.norm, backbone.layer5.2.conv.3, backbone.layer5.2.conv.3.conv, backbone.layer5.2.conv.3.norm, backbone.layer5.2.conv.4, backbone.layer5.2.conv.4.conv, backbone.layer5.2.conv.4.norm, backbone.layer5.2.conv.5, backbone.layer5.2.conv.5.conv, backbone.layer5.2.conv.5.norm, backbone.layer5.2.conv3x3, backbone.layer5.2.conv3x3.conv, backbone.layer5.2.conv3x3.norm, backbone.layer5.2.dense_norm, backbone.layer5.2.fuse_conv, backbone.layer5.2.norm.0, backbone.layer5.2.norm.1, backbone.layer5.2.norm.2, backbone.layer5.2.norm.3, backbone.layer5.2.norm.4, backbone.layer5.2.norm.5, backbone.layer6, backbone.layer6.0, backbone.layer6.0.act, backbone.layer6.0.conv.0, backbone.layer6.0.conv.0.conv, backbone.layer6.0.conv.0.norm, backbone.layer6.0.conv.1, backbone.layer6.0.conv.1.conv, backbone.layer6.0.conv.1.norm, backbone.layer6.0.conv.2, backbone.layer6.0.conv.2.conv, backbone.layer6.0.conv.2.norm, backbone.layer6.0.conv.3, backbone.layer6.0.conv.3.conv, backbone.layer6.0.conv.3.norm, backbone.layer6.0.conv.4, backbone.layer6.0.conv.4.conv, backbone.layer6.0.conv.4.norm, backbone.layer6.0.conv.5, backbone.layer6.0.conv.5.conv, backbone.layer6.0.conv.5.norm, backbone.layer6.0.conv3x3, backbone.layer6.0.conv3x3.conv, backbone.layer6.0.conv3x3.norm, backbone.layer6.0.dense_norm, backbone.layer6.0.fuse_conv, backbone.layer6.0.norm.0, backbone.layer6.0.norm.1, backbone.layer6.0.norm.2, backbone.layer6.0.norm.3, backbone.layer6.0.norm.4, backbone.layer6.0.norm.5, backbone.layer6.1, backbone.layer6.1.act, backbone.layer6.1.conv.0, backbone.layer6.1.conv.0.conv, backbone.layer6.1.conv.0.norm, backbone.layer6.1.conv.1, backbone.layer6.1.conv.1.conv, backbone.layer6.1.conv.1.norm, backbone.layer6.1.conv.2, backbone.layer6.1.conv.2.conv, backbone.layer6.1.conv.2.norm, backbone.layer6.1.conv.3, backbone.layer6.1.conv.3.conv, backbone.layer6.1.conv.3.norm, backbone.layer6.1.conv.4, backbone.layer6.1.conv.4.conv, backbone.layer6.1.conv.4.norm, backbone.layer6.1.conv.5, backbone.layer6.1.conv.5.conv, backbone.layer6.1.conv.5.norm, backbone.layer6.1.conv3x3, backbone.layer6.1.conv3x3.conv, backbone.layer6.1.conv3x3.norm, backbone.layer6.1.dense_norm, backbone.layer6.1.fuse_conv, backbone.layer6.1.norm.0, backbone.layer6.1.norm.1, backbone.layer6.1.norm.2, backbone.layer6.1.norm.3, backbone.layer6.1.norm.4, backbone.layer6.1.norm.5, backbone.layer6.2, backbone.layer6.2.act, backbone.layer6.2.conv.0, backbone.layer6.2.conv.0.conv, backbone.layer6.2.conv.0.norm, backbone.layer6.2.conv.1, backbone.layer6.2.conv.1.conv, backbone.layer6.2.conv.1.norm, backbone.layer6.2.conv.2, backbone.layer6.2.conv.2.conv, backbone.layer6.2.conv.2.norm, backbone.layer6.2.conv.3, backbone.layer6.2.conv.3.conv, backbone.layer6.2.conv.3.norm, backbone.layer6.2.conv.4, backbone.layer6.2.conv.4.conv, backbone.layer6.2.conv.4.norm, backbone.layer6.2.conv.5, backbone.layer6.2.conv.5.conv, backbone.layer6.2.conv.5.norm, backbone.layer6.2.conv3x3, backbone.layer6.2.conv3x3.conv, backbone.layer6.2.conv3x3.norm, backbone.layer6.2.dense_norm, backbone.layer6.2.fuse_conv, backbone.layer6.2.norm.0, backbone.layer6.2.norm.1, backbone.layer6.2.norm.2, backbone.layer6.2.norm.3, backbone.layer6.2.norm.4, backbone.layer6.2.norm.5, backbone.layer7, backbone.layer7.0, backbone.layer7.0.act, backbone.layer7.0.conv.0, backbone.layer7.0.conv.0.conv, backbone.layer7.0.conv.0.norm, backbone.layer7.0.conv.1, backbone.layer7.0.conv.1.conv, backbone.layer7.0.conv.1.norm, backbone.layer7.0.conv.2, backbone.layer7.0.conv.2.conv, backbone.layer7.0.conv.2.norm, backbone.layer7.0.conv.3, backbone.layer7.0.conv.3.conv, backbone.layer7.0.conv.3.norm, backbone.layer7.0.conv.4, backbone.layer7.0.conv.4.conv, backbone.layer7.0.conv.4.norm, backbone.layer7.0.conv.5, backbone.layer7.0.conv.5.conv, backbone.layer7.0.conv.5.norm, backbone.layer7.0.conv3x3, backbone.layer7.0.conv3x3.conv, backbone.layer7.0.conv3x3.norm, backbone.layer7.0.dense_norm, backbone.layer7.0.fuse_conv, backbone.layer7.0.norm.0, backbone.layer7.0.norm.1, backbone.layer7.0.norm.2, backbone.layer7.0.norm.3, backbone.layer7.0.norm.4, backbone.layer7.0.norm.5, bbox_head.loss_bg, bbox_head.loss_cls, data_preprocessor\n",
            "07/22 11:37:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::batch_norm encountered 2 time(s)\n",
            "\n",
            "+----------------------------------+----------------------+------------+--------------+\n",
            "|\u001b[1m \u001b[0m\u001b[1mmodule                          \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#parameters or shape\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#flops    \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#activations\u001b[0m\u001b[1m \u001b[0m|\n",
            "+----------------------------------+----------------------+------------+--------------+\n",
            "| model                            | 2.18M                | 57.499M    | 0.453M       |\n",
            "|  backbone                        |  2.165M              |  49.398M   |  0.424M      |\n",
            "|   backbone.conv1                 |   0.464K             |   4.276M   |   0.147M     |\n",
            "|    backbone.conv1.conv           |    0.432K            |    3.981M  |    0.147M    |\n",
            "|    backbone.conv1.norm           |    32                |    0.295M  |    0         |\n",
            "|   backbone.layer1.0              |   6.72K              |   21.234M  |   0.147M     |\n",
            "|    backbone.layer1.0.conv3x3     |    2.352K            |            |              |\n",
            "|    backbone.layer1.0.conv        |    1.824K            |            |              |\n",
            "|    backbone.layer1.0.norm        |    0.192K            |            |              |\n",
            "|    backbone.layer1.0.dense_norm  |    32                |            |              |\n",
            "|    backbone.layer1.0.fuse_conv   |    2.32K             |    21.234M |    0.147M    |\n",
            "|   backbone.layer2                |   13.44K             |   10.617M  |   73.728K    |\n",
            "|    backbone.layer2.0             |    6.72K             |    5.308M  |    36.864K   |\n",
            "|    backbone.layer2.1             |    6.72K             |    5.308M  |    36.864K   |\n",
            "|   backbone.layer3                |   67.968K            |   13.271M  |   55.296K    |\n",
            "|    backbone.layer3.0             |    16.512K           |    2.654M  |    18.432K   |\n",
            "|    backbone.layer3.1             |    25.728K           |    5.308M  |    18.432K   |\n",
            "|    backbone.layer3.2             |    25.728K           |    5.308M  |    18.432K   |\n",
            "|   backbone.layer4                |   0.214M             |            |              |\n",
            "|    backbone.layer4.0             |    43.2K             |            |              |\n",
            "|    backbone.layer4.1             |    57.024K           |            |              |\n",
            "|    backbone.layer4.2             |    57.024K           |            |              |\n",
            "|    backbone.layer4.3             |    57.024K           |            |              |\n",
            "|   backbone.layer5                |   0.283M             |            |              |\n",
            "|    backbone.layer5.0             |    82.176K           |            |              |\n",
            "|    backbone.layer5.1             |    0.101M            |            |              |\n",
            "|    backbone.layer5.2             |    0.101M            |            |              |\n",
            "|   backbone.layer6                |   0.818M             |            |              |\n",
            "|    backbone.layer6.0             |    0.208M            |            |              |\n",
            "|    backbone.layer6.1             |    0.305M            |            |              |\n",
            "|    backbone.layer6.2             |    0.305M            |            |              |\n",
            "|   backbone.layer7.0              |   0.761M             |            |              |\n",
            "|    backbone.layer7.0.conv3x3     |    0.226M            |            |              |\n",
            "|    backbone.layer7.0.conv        |    0.305M            |            |              |\n",
            "|    backbone.layer7.0.norm        |    2.688K            |            |              |\n",
            "|    backbone.layer7.0.dense_norm  |    0.448K            |            |              |\n",
            "|    backbone.layer7.0.fuse_conv   |    0.226M            |            |              |\n",
            "|  bbox_head                       |  14.067K             |  8.101M    |  29.376K     |\n",
            "|   bbox_head.convs_bridge.0       |   13.92K             |   8.018M   |   27.648K    |\n",
            "|    bbox_head.convs_bridge.0.0    |    13.824K           |    7.963M  |    27.648K   |\n",
            "|    bbox_head.convs_bridge.0.1    |    96                |    55.296K |    0         |\n",
            "|   bbox_head.convs_pred.0         |   0.147K             |   82.944K  |   1.728K     |\n",
            "|    bbox_head.convs_pred.0.weight |    (3, 48, 1, 1)     |            |              |\n",
            "|    bbox_head.convs_pred.0.bias   |    (3,)              |            |              |\n",
            "+----------------------------------+----------------------+------------+--------------+\n",
            "\n",
            "========================================\n",
            "    Input Shape     :  [1, 3, 192, 192]  \n",
            "    Model Flops     :      57.499M       \n",
            "  Model Parameters  :       2.18M        \n",
            "========================================\n",
            "loading annotations into memory...\n",
            "Done (t=41.77s)\n",
            "creating index...\n",
            "index created!\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "   Mode     Epoch      loss      fgnd      bgnd       P         R         F1       eta    \n",
            "  train     1/100     0.4408    0.3271    0.1137    0.0063    0.1114     0.01   4 days, 4:44:41:  37%|▎| 130/349 [22:24<Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 634, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1295, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 113, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 424, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/sscma.train\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/content/ModelAssistant/sscma/tools/train.py\", line 222, in main\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1777, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 96, in run\n",
            "    self.run_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 112, in run_epoch\n",
            "    for idx, data_batch in enumerate(self.dataloader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
            "    with torch.autograd.profiler.record_function(self._profile_name):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\", line 507, in __exit__\n",
            "    torch.ops.profiler._record_function_exit._RecordFunction(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 286, in __call__\n",
            "    def __call__(self, *args, **kwargs):\n",
            "KeyboardInterrupt\n",
            "  train     1/100     0.4408    0.3271    0.1137    0.0063    0.1114     0.01   4 days, 4:44:41:  37%|▎| 130/349 [22:31<\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# As anotações precisam estar no formato COCO, apesar de treinar em Yolo.\n",
        "%cd ..\n",
        "%ls\n",
        "%cd /content/ModelAssistant\n",
        "!sscma.train configs/fomo/fomo_mobnetv2_0.35_x8_abl_coco.py \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Dog_Pee_Detect \\\n",
        "    num_classes=2 \\\n",
        "    epochs=100  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=/content/drive/MyDrive/DogStainAmplified-5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copiar os arquivos de compilação para o Google Drive"
      ],
      "metadata": {
        "id": "92M9ANNeo0if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cp -r Dog_Pee_Detect/* /content/drive/MyDrive/Dog_Pee_Detect/"
      ],
      "metadata": {
        "id": "tP6YC8CjotHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "818ba5d2-5f89-464d-c96c-c993a09c6422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: target '/content/drive/MyDrive/Dog_Pee_Detect/' is not a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAGYO1a45boj"
      },
      "source": [
        "## 📦Export the model\n",
        "After training, you can export the model to the format for deployment. SSCMA supports exporting to ONNX, and TensorFlow Lite at present.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "O arquivo gerado vai ser com extensão tflite vela uint8\n",
        "\n",
        "```bash\n",
        "python3 tools/export.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRNGDHls5bok"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "with open('Dog_Pee_Detect/last_checkpoint', 'r') as f:\n",
        "\tos.environ['CHECKPOINT_FILE_PATH'] = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO_bt2Qq5bok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db51584-79b7-4c3e-d373-0c32213457d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using automatically generated input type (from config 'fomo_mobnetv2_0.35_x8_abl_coco.py'): image\n",
            "Using automatically generated input shape (from config 'fomo_mobnetv2_0.35_x8_abl_coco.py'): [1, 3, 192, 192]\n",
            "07/20 17:45:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1707504330\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.10.0\n",
            "    MMEngine: 0.10.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1707504330\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "07/20 17:45:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "albu_train_transforms = [\n",
            "    dict(limit=30, type='Rotate'),\n",
            "    dict(\n",
            "        brightness_limit=0.3,\n",
            "        contrast_limit=0.3,\n",
            "        p=0.5,\n",
            "        type='RandomBrightnessContrast'),\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "    dict(p=0.5, type='HorizontalFlip'),\n",
            "]\n",
            "batch = 16\n",
            "custom_imports = dict(\n",
            "    allow_failed_imports=False, imports=[\n",
            "        'sscma',\n",
            "    ])\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        0,\n",
            "        0,\n",
            "        0,\n",
            "    ],\n",
            "    pad_size_divisor=32,\n",
            "    std=[\n",
            "        255.0,\n",
            "        255.0,\n",
            "        255.0,\n",
            "    ],\n",
            "    type='mmdet.DetDataPreprocessor')\n",
            "data_root = '/content/drive/MyDrive/DogStainAmplified-5'\n",
            "dataset_type = 'CustomFomoCocoDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(interval=5, type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(score_thr=0.8, type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "find_unused_parameters = True\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "input_type = 'image'\n",
            "load_from = None\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "lr = 0.001\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        out_indices=(2, ), rep=True, type='MobileNetv2', widen_factor=0.35),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0,\n",
            "            0,\n",
            "            0,\n",
            "        ],\n",
            "        pad_size_divisor=32,\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    head=dict(\n",
            "        act_cfg='ReLU6',\n",
            "        input_channels=[\n",
            "            32,\n",
            "        ],\n",
            "        loss_bg=dict(reduction='none', type='BCEWithLogitsLoss'),\n",
            "        loss_cls=dict(\n",
            "            pos_weight=40, reduction='none', type='BCEWithLogitsLoss'),\n",
            "        middle_channel=48,\n",
            "        num_classes=2,\n",
            "        type='FomoHead'),\n",
            "    skip_preprocessor=True,\n",
            "    type='Fomo')\n",
            "momentum = (\n",
            "    0.9,\n",
            "    0.99,\n",
            ")\n",
            "num_classes = 2\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(\n",
            "        betas=(\n",
            "            0.9,\n",
            "            0.99,\n",
            "        ),\n",
            "        eps=1e-07,\n",
            "        lr=0.001,\n",
            "        type='Adam',\n",
            "        weight_decay=0.0005))\n",
            "param_scheduler = [\n",
            "    dict(begin=0, by_epoch=False, end=30, start_factor=0.001, type='LinearLR'),\n",
            "    dict(\n",
            "        begin=1,\n",
            "        by_epoch=True,\n",
            "        end=500,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            100,\n",
            "            200,\n",
            "            250,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "resume = False\n",
            "save_interval = 5\n",
            "test_cfg = dict()\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='/content/drive/MyDrive/DogStainAmplified-5',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='mmdet.Resize'),\n",
            "            dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'fomo_mask',\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='CustomFomoCocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(round_up=False, shuffle=True, type='DefaultSampler'))\n",
            "test_evaluator = dict(type='FomoMetric')\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='mmdet.Resize'),\n",
            "    dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'fomo_mask',\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(by_epoch=True, max_epochs=10, val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='/content/drive/MyDrive/DogStainAmplified-5',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='mmdet.Resize'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(limit=30, type='Rotate'),\n",
            "                    dict(\n",
            "                        brightness_limit=0.3,\n",
            "                        contrast_limit=0.3,\n",
            "                        p=0.5,\n",
            "                        type='RandomBrightnessContrast'),\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                    dict(p=0.5, type='HorizontalFlip'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'fomo_mask',\n",
            "                    'img_path',\n",
            "                    'img_id',\n",
            "                    'instances',\n",
            "                    'img_shape',\n",
            "                    'ori_shape',\n",
            "                    'gt_bboxes',\n",
            "                    'gt_bboxes_labels',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='CustomFomoCocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(round_up=False, shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='mmdet.Resize'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(limit=30, type='Rotate'),\n",
            "            dict(\n",
            "                brightness_limit=0.3,\n",
            "                contrast_limit=0.3,\n",
            "                p=0.5,\n",
            "                type='RandomBrightnessContrast'),\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "            dict(p=0.5, type='HorizontalFlip'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'fomo_mask',\n",
            "            'img_path',\n",
            "            'img_id',\n",
            "            'instances',\n",
            "            'img_shape',\n",
            "            'ori_shape',\n",
            "            'gt_bboxes',\n",
            "            'gt_bboxes_labels',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 1\n",
            "val_cfg = dict()\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='/content/drive/MyDrive/DogStainAmplified-5',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='mmdet.Resize'),\n",
            "            dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'fomo_mask',\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='CustomFomoCocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(round_up=False, shuffle=True, type='DefaultSampler'))\n",
            "val_evaluator = dict(type='FomoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 1\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    fomo=True,\n",
            "    name='visualizer',\n",
            "    type='FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.35\n",
            "width = 192\n",
            "work_dir = '/content/drive/MyDrive/Dog_Pee_Detect'\n",
            "workers = 1\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/drive/MyDrive/Dog_Pee_Detect/20240720_174525'}\n",
            "2024-07-20 17:45:26.996079: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-20 17:45:26.996132: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-20 17:45:26.997755: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-20 17:45:27.006046: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-20 17:45:28.308912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "07/20 17:45:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "07/20 17:45:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "Loads checkpoint by local backend from path: /content/ModelAssistant/Dog_Pee_Detect/epoch_100.pth\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "  0%|                     | 0/100 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "100%|███████████| 100/100 [00:03<00:00, 30.91it/s]\n",
            "INFO (tinynn.converter.base) Generated model saved to /content/ModelAssistant/Dog_Pee_Detect/epoch_100_int8.tflite\n",
            "Warning: Using internal-default values for system configuration\n",
            "Warning: Using internal-default values for memory mode\n",
            "Warning: TRANSPOSE 'fuse_transform_1' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 24, 24, 3] and permutation is: [0 2 3 1]\n",
            "\n",
            "Network summary for epoch_100_int8\n",
            "Accelerator configuration                Ethos_U55_64\n",
            "System configuration                 internal-default\n",
            "Memory mode                          internal-default\n",
            "Accelerator clock                                 500 MHz\n",
            "Design peak SRAM bandwidth                       4.00 GB/s\n",
            "Design peak Off-chip Flash bandwidth             0.50 GB/s\n",
            "\n",
            "Total SRAM used                                293.02 KiB\n",
            "Total Off-chip Flash used                       41.70 KiB\n",
            "\n",
            "CPU operators = 1 (2.4%)\n",
            "NPU operators = 40 (97.6%)\n",
            "\n",
            "Average SRAM bandwidth                           1.48 GB/s\n",
            "Input   SRAM bandwidth                           2.41 MB/batch\n",
            "Weight  SRAM bandwidth                           1.03 MB/batch\n",
            "Output  SRAM bandwidth                           1.49 MB/batch\n",
            "Total   SRAM bandwidth                           4.93 MB/batch\n",
            "Total   SRAM bandwidth            per input      4.93 MB/inference (batch size 1)\n",
            "\n",
            "Average Off-chip Flash bandwidth                 0.01 GB/s\n",
            "Input   Off-chip Flash bandwidth                 0.00 MB/batch\n",
            "Weight  Off-chip Flash bandwidth                 0.04 MB/batch\n",
            "Output  Off-chip Flash bandwidth                 0.00 MB/batch\n",
            "Total   Off-chip Flash bandwidth                 0.04 MB/batch\n",
            "Total   Off-chip Flash bandwidth  per input      0.04 MB/inference (batch size 1)\n",
            "\n",
            "Neural network macs                          57151872 MACs/batch\n",
            "Network Tops/s                                   0.03 Tops/s\n",
            "\n",
            "NPU cycles                                    1605430 cycles/batch\n",
            "SRAM Access cycles                             538248 cycles/batch\n",
            "DRAM Access cycles                                  0 cycles/batch\n",
            "On-chip Flash Access cycles                         0 cycles/batch\n",
            "Off-chip Flash Access cycles                     3840 cycles/batch\n",
            "Total cycles                                  1669857 cycles/batch\n",
            "\n",
            "Batch Inference time                 3.34 ms,  299.43 inferences/s (batch size 1)\n",
            "\n",
            "TFLite: Successfully export model: /content/ModelAssistant/Dog_Pee_Detect/epoch_100_int8.tflite\n",
            "WARNING (tinynn.converter.operators.optimize) Cannot passthrough transpose downward around requantizable ops\n",
            "WARNING (tinynn.converter.operators.optimize) Cannot passthrough transpose upward around requantizable ops\n",
            "INFO (tinynn.converter.base) Generated model saved to /content/ModelAssistant/Dog_Pee_Detect/epoch_100_float32.tflite\n",
            "Warning: Using internal-default values for system configuration\n",
            "Warning: Using internal-default values for memory mode\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '71_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: inputs.1, 71_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '82_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 71_te_transform_1_te_transform_2, fuse_attr_8_reshape, 82_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '94_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 82_te_transform, fuse_attr_9_reshape, 94_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '94_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 94_te_transform, 94_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '104_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 94_te_transform_1_te_transform_2, fuse_attr_10_reshape, 104_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '117_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 104_te_transform, fuse_attr_11_reshape, 117_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '117_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 117_te_transform, 117_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '127_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 117_te_transform_1_te_transform_2, fuse_attr_12_reshape, 127_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '137_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 127_te_transform, fuse_attr_13_reshape, 137_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '161_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 137_te_transform, fuse_attr_14_reshape, 161_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '172_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 161_te_transform, fuse_attr_15_reshape, 172_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '33_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 172_te_transform, fuse_attr_16_reshape, 33_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for SOFTMAX '33_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 33_transform, 33_transform_1\n",
            "Warning: TRANSPOSE '33' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor '33_transform_1' has data type: float32, Tensor '33' has data type: float32\n",
            "\n",
            "Network summary for epoch_100_float32\n",
            "Accelerator configuration                Ethos_U55_64\n",
            "System configuration                 internal-default\n",
            "Memory mode                          internal-default\n",
            "Accelerator clock                                 500 MHz\n",
            "\n",
            "\n",
            "CPU operators = 14 (100.0%)\n",
            "NPU operators = 0 (0.0%)\n",
            "\n",
            "Neural network macs                                 0 MACs/batch\n",
            "Network Tops/s                                    nan Tops/s\n",
            "\n",
            "NPU cycles                                          0 cycles/batch\n",
            "SRAM Access cycles                                  0 cycles/batch\n",
            "DRAM Access cycles                                  0 cycles/batch\n",
            "On-chip Flash Access cycles                         0 cycles/batch\n",
            "Off-chip Flash Access cycles                        0 cycles/batch\n",
            "Total cycles                                        0 cycles/batch\n",
            "\n",
            "Batch Inference time                 0.00 ms,     nan inferences/s (batch size 1)\n",
            "\n",
            "TFLite: Successfully export model: /content/ModelAssistant/Dog_Pee_Detect/epoch_100_float32.tflite\n",
            "ONNX: Ignoring unsupported precision: int8\n",
            "Exported graph: graph(%input : Float(1, 3, 192, 192, strides=[110592, 36864, 192, 1], requires_grad=0, device=cpu),\n",
            "      %backbone.layer1.0.fuse_conv.weight : Float(16, 16, 3, 3, strides=[9, 144, 3, 1], requires_grad=1, device=cpu),\n",
            "      %backbone.layer1.0.fuse_conv.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
            "      %backbone.layer2.0.fuse_conv.weight : Float(16, 16, 3, 3, strides=[9, 144, 3, 1], requires_grad=1, device=cpu),\n",
            "      %backbone.layer2.0.fuse_conv.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
            "      %backbone.layer2.1.fuse_conv.weight : Float(16, 16, 3, 3, strides=[9, 144, 3, 1], requires_grad=1, device=cpu),\n",
            "      %backbone.layer2.1.fuse_conv.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
            "      %backbone.layer3.0.fuse_conv.weight : Float(32, 16, 3, 3, strides=[9, 288, 3, 1], requires_grad=1, device=cpu),\n",
            "      %backbone.layer3.0.fuse_conv.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
            "      %backbone.layer3.1.fuse_conv.weight : Float(32, 32, 3, 3, strides=[9, 288, 3, 1], requires_grad=1, device=cpu),\n",
            "      %backbone.layer3.1.fuse_conv.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
            "      %backbone.layer3.2.fuse_conv.weight : Float(32, 32, 3, 3, strides=[9, 288, 3, 1], requires_grad=1, device=cpu),\n",
            "      %backbone.layer3.2.fuse_conv.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.convs_pred.0.weight : Float(3, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.convs_pred.0.bias : Float(3, strides=[1], requires_grad=1, device=cpu),\n",
            "      %onnx::Conv_1504 : Float(16, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1505 : Float(16, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1507 : Float(48, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1508 : Float(48, strides=[1], requires_grad=0, device=cpu)):\n",
            "  %/backbone/conv1/conv/Conv_output_0 : Float(1, 16, 96, 96, strides=[147456, 9216, 96, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/conv1/conv/Conv\"](%input, %onnx::Conv_1504, %onnx::Conv_1505), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/conv1/act/Constant_output_0 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/backbone/conv1/act/Constant\"](), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU6::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1508:0\n",
            "  %/backbone/conv1/act/Constant_1_output_0 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"/backbone/conv1/act/Constant_1\"](), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU6::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1508:0\n",
            "  %/backbone/conv1/act/Clip_output_0 : Float(1, 16, 96, 96, strides=[147456, 9216, 96, 1], requires_grad=0, device=cpu) = onnx::Clip[onnx_name=\"/backbone/conv1/act/Clip\"](%/backbone/conv1/conv/Conv_output_0, %/backbone/conv1/act/Constant_output_0, %/backbone/conv1/act/Constant_1_output_0), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU6::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1508:0\n",
            "  %/backbone/layer1/layer1.0/fuse_conv/Conv_output_0 : Float(1, 16, 96, 96, strides=[147456, 9216, 96, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/layer1/layer1.0/fuse_conv/Conv\"](%/backbone/conv1/act/Clip_output_0, %backbone.layer1.0.fuse_conv.weight, %backbone.layer1.0.fuse_conv.bias), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/torch.nn.modules.container.Sequential::layer1/sscma.models.layers.rep.RepConv1x1::layer1.0/torch.nn.modules.conv.Conv2d::fuse_conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/layer1/layer1.0/act/Relu_output_0 : Float(1, 16, 96, 96, strides=[147456, 9216, 96, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/layer1/layer1.0/act/Relu\"](%/backbone/layer1/layer1.0/fuse_conv/Conv_output_0), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/torch.nn.modules.container.Sequential::layer1/sscma.models.layers.rep.RepConv1x1::layer1.0/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/layer2/layer2.0/fuse_conv/Conv_output_0 : Float(1, 16, 48, 48, strides=[36864, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/layer2/layer2.0/fuse_conv/Conv\"](%/backbone/layer1/layer1.0/act/Relu_output_0, %backbone.layer2.0.fuse_conv.weight, %backbone.layer2.0.fuse_conv.bias), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/torch.nn.modules.container.Sequential::layer2/sscma.models.layers.rep.RepConv1x1::layer2.0/torch.nn.modules.conv.Conv2d::fuse_conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/layer2/layer2.0/act/Relu_output_0 : Float(1, 16, 48, 48, strides=[36864, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/layer2/layer2.0/act/Relu\"](%/backbone/layer2/layer2.0/fuse_conv/Conv_output_0), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/torch.nn.modules.container.Sequential::layer2/sscma.models.layers.rep.RepConv1x1::layer2.0/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/layer2/layer2.1/fuse_conv/Conv_output_0 : Float(1, 16, 48, 48, strides=[36864, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/layer2/layer2.1/fuse_conv/Conv\"](%/backbone/layer2/layer2.0/act/Relu_output_0, %backbone.layer2.1.fuse_conv.weight, %backbone.layer2.1.fuse_conv.bias), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/torch.nn.modules.container.Sequential::layer2/sscma.models.layers.rep.RepConv1x1::layer2.1/torch.nn.modules.conv.Conv2d::fuse_conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/layer2/layer2.1/act/Relu_output_0 : Float(1, 16, 48, 48, strides=[36864, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/layer2/layer2.1/act/Relu\"](%/backbone/layer2/layer2.1/fuse_conv/Conv_output_0), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/torch.nn.modules.container.Sequential::layer2/sscma.models.layers.rep.RepConv1x1::layer2.1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/layer3/layer3.0/fuse_conv/Conv_output_0 : Float(1, 32, 24, 24, strides=[18432, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/layer3/layer3.0/fuse_conv/Conv\"](%/backbone/layer2/layer2.1/act/Relu_output_0, %backbone.layer3.0.fuse_conv.weight, %backbone.layer3.0.fuse_conv.bias), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/torch.nn.modules.container.Sequential::layer3/sscma.models.layers.rep.RepConv1x1::layer3.0/torch.nn.modules.conv.Conv2d::fuse_conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/layer3/layer3.0/act/Relu_output_0 : Float(1, 32, 24, 24, strides=[18432, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/layer3/layer3.0/act/Relu\"](%/backbone/layer3/layer3.0/fuse_conv/Conv_output_0), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/torch.nn.modules.container.Sequential::layer3/sscma.models.layers.rep.RepConv1x1::layer3.0/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/layer3/layer3.1/fuse_conv/Conv_output_0 : Float(1, 32, 24, 24, strides=[18432, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/layer3/layer3.1/fuse_conv/Conv\"](%/backbone/layer3/layer3.0/act/Relu_output_0, %backbone.layer3.1.fuse_conv.weight, %backbone.layer3.1.fuse_conv.bias), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/torch.nn.modules.container.Sequential::layer3/sscma.models.layers.rep.RepConv1x1::layer3.1/torch.nn.modules.conv.Conv2d::fuse_conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/layer3/layer3.1/act/Relu_output_0 : Float(1, 32, 24, 24, strides=[18432, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/layer3/layer3.1/act/Relu\"](%/backbone/layer3/layer3.1/fuse_conv/Conv_output_0), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/torch.nn.modules.container.Sequential::layer3/sscma.models.layers.rep.RepConv1x1::layer3.1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/layer3/layer3.2/fuse_conv/Conv_output_0 : Float(1, 32, 24, 24, strides=[18432, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/layer3/layer3.2/fuse_conv/Conv\"](%/backbone/layer3/layer3.1/act/Relu_output_0, %backbone.layer3.2.fuse_conv.weight, %backbone.layer3.2.fuse_conv.bias), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/torch.nn.modules.container.Sequential::layer3/sscma.models.layers.rep.RepConv1x1::layer3.2/torch.nn.modules.conv.Conv2d::fuse_conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/layer3/layer3.2/act/Relu_output_0 : Float(1, 32, 24, 24, strides=[18432, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/layer3/layer3.2/act/Relu\"](%/backbone/layer3/layer3.2/fuse_conv/Conv_output_0), scope: sscma.models.detectors.fomo.Fomo::/sscma.models.backbones.MobileNetv2.MobileNetv2::backbone/torch.nn.modules.container.Sequential::layer3/sscma.models.layers.rep.RepConv1x1::layer3.2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/convs_bridge.0/convs_bridge.0.0/Conv_output_0 : Float(1, 48, 24, 24, strides=[27648, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/convs_bridge.0/convs_bridge.0.0/Conv\"](%/backbone/layer3/layer3.2/act/Relu_output_0, %onnx::Conv_1507, %onnx::Conv_1508), scope: sscma.models.detectors.fomo.Fomo::/torch.nn.modules.container.Sequential::convs_bridge.0/torch.nn.modules.conv.Conv2d::convs_bridge.0.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/convs_bridge.0/convs_bridge.0.2/Constant_output_0 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/convs_bridge.0/convs_bridge.0.2/Constant\"](), scope: sscma.models.detectors.fomo.Fomo::/torch.nn.modules.container.Sequential::convs_bridge.0/torch.nn.modules.activation.ReLU6::convs_bridge.0.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1506:0\n",
            "  %/convs_bridge.0/convs_bridge.0.2/Constant_1_output_0 : Float(device=cpu) = onnx::Constant[value={6}, onnx_name=\"/convs_bridge.0/convs_bridge.0.2/Constant_1\"](), scope: sscma.models.detectors.fomo.Fomo::/torch.nn.modules.container.Sequential::convs_bridge.0/torch.nn.modules.activation.ReLU6::convs_bridge.0.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1506:0\n",
            "  %/convs_bridge.0/convs_bridge.0.2/Clip_output_0 : Float(1, 48, 24, 24, strides=[27648, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Clip[onnx_name=\"/convs_bridge.0/convs_bridge.0.2/Clip\"](%/convs_bridge.0/convs_bridge.0.0/Conv_output_0, %/convs_bridge.0/convs_bridge.0.2/Constant_output_0, %/convs_bridge.0/convs_bridge.0.2/Constant_1_output_0), scope: sscma.models.detectors.fomo.Fomo::/torch.nn.modules.container.Sequential::convs_bridge.0/torch.nn.modules.activation.ReLU6::convs_bridge.0.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1506:0\n",
            "  %/convs_pred.0/Conv_output_0 : Float(1, 3, 24, 24, strides=[1728, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.0/Conv\"](%/convs_bridge.0/convs_bridge.0.2/Clip_output_0, %bbox_head.convs_pred.0.weight, %bbox_head.convs_pred.0.bias), scope: sscma.models.detectors.fomo.Fomo::/torch.nn.modules.conv.Conv2d::convs_pred.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Transpose_output_0 : Float(1, 24, 24, 3, strides=[1728, 24, 1, 576], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1], onnx_name=\"/Transpose\"](%/convs_pred.0/Conv_output_0), scope: sscma.models.detectors.fomo.Fomo:: # /content/ModelAssistant/sscma/models/detectors/fomo.py:94:0\n",
            "  %output : Float(1, 24, 24, 3, strides=[1728, 72, 3, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=3, onnx_name=\"/Softmax\"](%/Transpose_output_0), scope: sscma.models.detectors.fomo.Fomo:: # /content/ModelAssistant/sscma/models/detectors/fomo.py:94:0\n",
            "  return (%output)\n",
            "\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "ONNX: Successfully export model: /content/ModelAssistant/Dog_Pee_Detect/epoch_100_float32.onnx\n",
            "pnnxparam = /content/ModelAssistant/Dog_Pee_Detect/epoch_100_float.pnnx.param\n",
            "pnnxbin = /content/ModelAssistant/Dog_Pee_Detect/epoch_100_float.pnnx.bin\n",
            "pnnxpy = /content/ModelAssistant/Dog_Pee_Detect/epoch_100_float.pnnx.py\n",
            "pnnxonnx = /content/ModelAssistant/Dog_Pee_Detect/epoch_100_float.pnnx.onnx\n",
            "ncnnparam = /content/ModelAssistant/Dog_Pee_Detect/epoch_100_float.ncnn.param\n",
            "ncnnbin = /content/ModelAssistant/Dog_Pee_Detect/epoch_100_float.ncnn.bin\n",
            "ncnnpy = /content/ModelAssistant/Dog_Pee_Detect/epoch_100_float.ncnn.py\n",
            "fp16 = 1\n",
            "optlevel = 2\n",
            "device = cpu\n",
            "inputshape = [1,3,192,192]f32\n",
            "inputshape2 = \n",
            "customop = \n",
            "moduleop = \n",
            "############# pass_level0\n",
            "inline module = sscma.models.backbones.MobileNetv2.MobileNetv2\n",
            "inline module = sscma.models.base.general.ConvNormActivation\n",
            "inline module = sscma.models.layers.rep.RepConv1x1\n",
            "inline module = sscma.models.backbones.MobileNetv2.MobileNetv2\n",
            "inline module = sscma.models.base.general.ConvNormActivation\n",
            "inline module = sscma.models.layers.rep.RepConv1x1\n",
            "\n",
            "----------------\n",
            "\n",
            "############# pass_level1\n",
            "############# pass_level2\n",
            "############# pass_level3\n",
            "############# pass_level4\n",
            "############# pass_level5\n",
            "############# pass_ncnn\n"
          ]
        }
      ],
      "source": [
        "!sscma.export configs/fomo/fomo_mobnetv2_0.35_x8_abl_coco.py $CHECKPOINT_FILE_PATH --cfg-options  \\\n",
        "    work_dir=/content/drive/MyDrive/Dog_Pee_Detect \\\n",
        "    num_classes=2 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=/content/drive/MyDrive/DogStainAmplified-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqh3sioV5bok"
      },
      "source": [
        "### 📝Evaluate the model\n",
        "After exporting the model, you can evaluate the model on the test dataset.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "\n",
        "```bash\n",
        "python3 tools/inference.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkFv1PmN5bok"
      },
      "source": [
        "### Evaluate the PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-jpU-ci5bok"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/fomo/fomo_mobnetv2_0.35_x8_abl_coco.py ${CHECKPOINT_FILE_PATH%.*}.pth \\\n",
        "--cfg-options  \\\n",
        "    work_dir=/content/drive/MyDrive/Dog_Pee_Detect \\\n",
        "    num_classes=2 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=/content/drive/MyDrive/DogStainAmplified-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk74BSV95bok"
      },
      "source": [
        "### Evaluate the ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q69FY4Ii5bok"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/fomo/fomo_mobnetv2_0.35_x8_abl_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.onnx \\\n",
        "--cfg-options  \\\n",
        "    work_dir=/content/drive/MyDrive/Dog_Pee_Detect \\\n",
        "    num_classes=2 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=/content/drive/MyDrive/DogStainAmplified-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWR4BU2t5bol"
      },
      "source": [
        "### Evaluate the TFLite FLOAT32 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXOod0UC5bol"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/fomo/fomo_mobnetv2_0.35_x8_abl_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=/content/drive/MyDrive/Dog_Pee_Detect \\\n",
        "    num_classes=2 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=/content/drive/MyDrive/DogStainAmplified-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dTE3uwc5bol"
      },
      "source": [
        "### Evaluate the TFLite INT8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLHPoLi_5bol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b936dd7-c2c5-4117-bd8e-bb97ccdc5421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using task type from config: mmdet\n",
            "Using dump path from checkpoint: /content/ModelAssistant/Dog_Pee_Detect/epoch_100_int8.pkl\n",
            "07/20 17:47:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1400381922\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.10.0\n",
            "    MMEngine: 0.10.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1400381922\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "07/20 17:47:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "albu_train_transforms = [\n",
            "    dict(limit=30, type='Rotate'),\n",
            "    dict(\n",
            "        brightness_limit=0.3,\n",
            "        contrast_limit=0.3,\n",
            "        p=0.5,\n",
            "        type='RandomBrightnessContrast'),\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "    dict(p=0.5, type='HorizontalFlip'),\n",
            "]\n",
            "batch = 16\n",
            "custom_imports = dict(\n",
            "    allow_failed_imports=False, imports=[\n",
            "        'sscma',\n",
            "    ])\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        0,\n",
            "        0,\n",
            "        0,\n",
            "    ],\n",
            "    pad_size_divisor=32,\n",
            "    std=[\n",
            "        255.0,\n",
            "        255.0,\n",
            "        255.0,\n",
            "    ],\n",
            "    type='mmdet.DetDataPreprocessor')\n",
            "data_root = '/content/drive/MyDrive/DogStainAmplified-5'\n",
            "dataset_type = 'CustomFomoCocoDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(interval=5, type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(score_thr=0.8, type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "find_unused_parameters = True\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "input_type = 'image'\n",
            "launcher = 'none'\n",
            "load_from = None\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "lr = 0.001\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        out_indices=(2, ), rep=True, type='MobileNetv2', widen_factor=0.35),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0,\n",
            "            0,\n",
            "            0,\n",
            "        ],\n",
            "        pad_size_divisor=32,\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    head=dict(\n",
            "        act_cfg='ReLU6',\n",
            "        input_channels=[\n",
            "            32,\n",
            "        ],\n",
            "        loss_bg=dict(reduction='none', type='BCEWithLogitsLoss'),\n",
            "        loss_cls=dict(\n",
            "            pos_weight=40, reduction='none', type='BCEWithLogitsLoss'),\n",
            "        middle_channel=48,\n",
            "        num_classes=2,\n",
            "        type='FomoHead'),\n",
            "    skip_preprocessor=True,\n",
            "    type='Fomo')\n",
            "momentum = (\n",
            "    0.9,\n",
            "    0.99,\n",
            ")\n",
            "num_classes = 2\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(\n",
            "        betas=(\n",
            "            0.9,\n",
            "            0.99,\n",
            "        ),\n",
            "        eps=1e-07,\n",
            "        lr=0.001,\n",
            "        type='Adam',\n",
            "        weight_decay=0.0005))\n",
            "param_scheduler = [\n",
            "    dict(begin=0, by_epoch=False, end=30, start_factor=0.001, type='LinearLR'),\n",
            "    dict(\n",
            "        begin=1,\n",
            "        by_epoch=True,\n",
            "        end=500,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            100,\n",
            "            200,\n",
            "            250,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "resume = False\n",
            "save_interval = 5\n",
            "test_cfg = dict()\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='/content/drive/MyDrive/DogStainAmplified-5',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='mmdet.Resize'),\n",
            "            dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'fomo_mask',\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='CustomFomoCocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(round_up=False, shuffle=True, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    dict(type='FomoMetric'),\n",
            "    dict(\n",
            "        out_file_path=\n",
            "        '/content/ModelAssistant/Dog_Pee_Detect/epoch_100_int8.pkl',\n",
            "        type='DumpResults'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='mmdet.Resize'),\n",
            "    dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'fomo_mask',\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(by_epoch=True, max_epochs=10, val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='/content/drive/MyDrive/DogStainAmplified-5',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='mmdet.Resize'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(limit=30, type='Rotate'),\n",
            "                    dict(\n",
            "                        brightness_limit=0.3,\n",
            "                        contrast_limit=0.3,\n",
            "                        p=0.5,\n",
            "                        type='RandomBrightnessContrast'),\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                    dict(p=0.5, type='HorizontalFlip'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'fomo_mask',\n",
            "                    'img_path',\n",
            "                    'img_id',\n",
            "                    'instances',\n",
            "                    'img_shape',\n",
            "                    'ori_shape',\n",
            "                    'gt_bboxes',\n",
            "                    'gt_bboxes_labels',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='CustomFomoCocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(round_up=False, shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='mmdet.Resize'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(limit=30, type='Rotate'),\n",
            "            dict(\n",
            "                brightness_limit=0.3,\n",
            "                contrast_limit=0.3,\n",
            "                p=0.5,\n",
            "                type='RandomBrightnessContrast'),\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "            dict(p=0.5, type='HorizontalFlip'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'fomo_mask',\n",
            "            'img_path',\n",
            "            'img_id',\n",
            "            'instances',\n",
            "            'img_shape',\n",
            "            'ori_shape',\n",
            "            'gt_bboxes',\n",
            "            'gt_bboxes_labels',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 1\n",
            "val_cfg = dict()\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='/content/drive/MyDrive/DogStainAmplified-5',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='mmdet.Resize'),\n",
            "            dict(downsample_factor=(8, ), num_classes=2, type='Bbox2FomoMask'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'fomo_mask',\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='CustomFomoCocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(round_up=False, shuffle=True, type='DefaultSampler'))\n",
            "val_evaluator = dict(type='FomoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 1\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    fomo=True,\n",
            "    name='visualizer',\n",
            "    type='FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.35\n",
            "width = 192\n",
            "work_dir = '/content/drive/MyDrive/Dog_Pee_Detect'\n",
            "workers = 1\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/drive/MyDrive/Dog_Pee_Detect/20240720_174703'}\n",
            "2024-07-20 17:47:05.474716: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-20 17:47:05.474768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-20 17:47:05.476290: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-20 17:47:05.483598: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-20 17:47:06.805235: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "07/20 17:47:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "07/20 17:47:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "07/20 17:47:10 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class FomoMetric.\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "  0% 0/529 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "07/20 17:47:10 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "07/20 17:47:10 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "100% 529/529 [00:08<00:00, 62.76it/s]\n",
            "{'P': 0.7857142857142857, 'R': 0.03125, 'F1': 0.060109289617486336}\n",
            "FPS: 145.056774 fram/s\n"
          ]
        }
      ],
      "source": [
        "!sscma.inference configs/fomo/fomo_mobnetv2_0.35_x8_abl_coco.py ${CHECKPOINT_FILE_PATH%.*}_int8.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=/content/drive/MyDrive/Dog_Pee_Detect \\\n",
        "    num_classes=2 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=/content/drive/MyDrive/DogStainAmplified-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IRSyppk5bol"
      },
      "source": [
        "## 🤖 Deploy the model\n",
        "After model training, evaluation and export, you can deploy the model to your device. You can refer to [Documentation](https://sensecraftma.seeed.cc/deploy/overview) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ6b6lR55bol",
        "outputId": "18746a70-ec7c-40c4-80b0-9e0c438cccb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 224K\n",
            "drwx------ 3 root root 4.0K Jul 20 17:45 \u001b[0m\u001b[01;34m20240720_174525\u001b[0m/\n",
            "drwx------ 3 root root 4.0K Jul 20 17:46 \u001b[01;34m20240720_174557\u001b[0m/\n",
            "drwx------ 3 root root 4.0K Jul 20 17:46 \u001b[01;34m20240720_174620\u001b[0m/\n",
            "drwx------ 3 root root 4.0K Jul 20 17:46 \u001b[01;34m20240720_174640\u001b[0m/\n",
            "drwx------ 3 root root 4.0K Jul 20 17:47 \u001b[01;34m20240720_174703\u001b[0m/\n",
            "-rw------- 1 root root 9.9K Jul 20 17:47 fomo_mobnetv2_0.35_x8_abl_coco.py\n",
            "-rw------- 1 root root  587 Jul 20 17:45 fomo_q_config.yml\n",
            "-rw------- 1 root root 183K Jul 20 17:45 fomo_q.pth\n",
            "-rw------- 1 root root 6.3K Jul 20 17:45 fomo_q.py\n",
            "drwx------ 2 root root 4.0K Jul 20 17:45 \u001b[01;34m__pycache__\u001b[0m/\n",
            "total 224K\n",
            "drwx------ 3 root root 4.0K Jul 20 17:45 \u001b[0m\u001b[01;34m20240720_174525\u001b[0m/\n",
            "drwx------ 3 root root 4.0K Jul 20 17:46 \u001b[01;34m20240720_174557\u001b[0m/\n",
            "drwx------ 3 root root 4.0K Jul 20 17:46 \u001b[01;34m20240720_174620\u001b[0m/\n",
            "drwx------ 3 root root 4.0K Jul 20 17:46 \u001b[01;34m20240720_174640\u001b[0m/\n",
            "drwx------ 3 root root 4.0K Jul 20 17:47 \u001b[01;34m20240720_174703\u001b[0m/\n",
            "-rw------- 1 root root 9.9K Jul 20 17:47 fomo_mobnetv2_0.35_x8_abl_coco.py\n",
            "-rw------- 1 root root  587 Jul 20 17:45 fomo_q_config.yml\n",
            "-rw------- 1 root root 183K Jul 20 17:45 fomo_q.pth\n",
            "-rw------- 1 root root 6.3K Jul 20 17:45 fomo_q.py\n",
            "drwx------ 2 root root 4.0K Jul 20 17:45 \u001b[01;34m__pycache__\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls -lh /content/drive/MyDrive/Dog_Pee_Detect/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTVJj84mCQmb"
      },
      "outputs": [],
      "source": [
        "!cp -r Dog_Pee_Detect /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9VnU1mk5bol"
      },
      "source": [
        "### Thanks for Trying Out SSCMA 🎉\n",
        "\n",
        "Congratulations, you have completed this tutorial. If you are interested in more application scenarios or our projects, please feel free to give [SSCMA](https://github.com/Seeed-Studio/ModelAssistant) a star ✨ on GitHub.\n",
        "\n",
        "If you have any questions about this tutorial, please also feel free to [submit an issue](https://github.com/Seeed-Studio/ModelAssistant/issues)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}